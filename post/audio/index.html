<!doctype html><html lang><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="ie=edge"><title>How is sound represented in code? | Samyak Sarnayak</title>
<meta name=description content="How is sound represented in code?"><meta property="og:site_name" content="Samyak Sarnayak"><meta property="og:title" content="How is sound represented in code? - Samyak Sarnayak"><meta property="og:description" content="An overview of how audio is represented as data."><meta property="og:image" content="https://samyak.me/images/mob.png"><meta name=keywords content><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css integrity=sha384-AfEj0r4/OFrOo5t7NnNe46zW/tFgW6x/bCJG8FqQCEo3+Aro6EYUG4+cU+KJWu/X crossorigin=anonymous><script defer src=https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.js integrity=sha384-g7c+Jr9ZivxKLnZTDUhnkOnsh30B4H0rpLUpJ4jAIKs4fnJI+sEnkvrMWph2EDg4 crossorigin=anonymous></script><script defer src=https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/contrib/auto-render.min.js integrity=sha384-mll67QQFJfxn0IYznZYonOWZ644AWYC+Pt2cHqMaRhXVrursRwvLnLaebdGIlYNa crossorigin=anonymous onload=renderMathInElement(document.body)></script><script data-goatcounter=https://samyak.goatcounter.com/count async src=//gc.zgo.at/count.js></script><meta name=keywords content="Samyak,Sarnayak,PES,Software"><link rel=icon type=image/svg href=https://samyak.me/img/logo.png><meta name=author content='samyak_sarnayak'><meta name=viewport content="width=device-width,initial-scale=1"><meta name=generator content="Hugo 0.146.3"><link rel=stylesheet href=https://samyak.me/sass/main.min.73561462541a05e8aca52f0d514d3498788c0fb7a1cfe783a809fda8d591f238.css type=text/css media=screen><link rel=stylesheet href=https://samyak.me/sass/custom.min.2802693dbd5b636f729bbbf8919cd162693901a6228f8dd88a6f1f496c619307.css></head><body><div class=line id=scrollIndicator></div><div class=main><div class=title><div class=name><h2><a href=https://samyak.me/ style=text-decoration:none;color:inherit>Samyak Sarnayak</a></h2></div><div class=color-scheme><input type=checkbox class=checkbox id=chk>
<label class=label for=chk><svg aria-hidden="true" focusable="false" data-prefix="fas" data-icon="sun" role="img" viewBox="0 0 512 512"><path fill="currentcolor" d="M256 160c-52.9.0-96 43.1-96 96s43.1 96 96 96 96-43.1 96-96-43.1-96-96-96zm246.4 80.5-94.7-47.3 33.5-100.4c4.5-13.6-8.4-26.5-21.9-21.9l-100.4 33.5-47.4-94.8c-6.4-12.8-24.6-12.8-31 0l-47.3 94.7L92.7 70.8c-13.6-4.5-26.5 8.4-21.9 21.9l33.5 100.4-94.7 47.4c-12.8 6.4-12.8 24.6.0 31l94.7 47.3-33.5 100.5c-4.5 13.6 8.4 26.5 21.9 21.9l100.4-33.5 47.3 94.7c6.4 12.8 24.6 12.8 31 0l47.3-94.7 100.4 33.5c13.6 4.5 26.5-8.4 21.9-21.9l-33.5-100.4 94.7-47.3c13-6.5 13-24.7.2-31.1zm-155.9 106c-49.9 49.9-131.1 49.9-181 0s-49.9-131.1.0-181 131.1-49.9 181 0 49.9 131.1.0 181z"/></svg><svg aria-hidden="true" focusable="false" data-prefix="fas" data-icon="moon" role="img" viewBox="0 0 512 512"><path fill="currentcolor" d="M283.211 512c78.962.0 151.079-35.925 198.857-94.792 7.068-8.708-.639-21.43-11.562-19.35-124.203 23.654-238.262-71.576-238.262-196.954.0-72.222 38.662-138.635 101.498-174.394 9.686-5.512 7.25-20.197-3.756-22.23A258.156 258.156.0 00283.211.0c-141.309.0-256 114.511-256 256 0 141.309 114.511 256 256 256z"/></svg><div class=ball></div></label></div></div><script>let currentTheme="light";const themeSetter=e=>{currentTheme=e,document.body.classList.toggle("dark"),localStorage.setItem("theme",e),blockSwitcher(),window.customThemeCallback&&customThemeCallback(e)},blockSwitcher=()=>[...document.getElementsByTagName("BLOCKQUOTE")].forEach(e=>e.classList.toggle("dark")),styleSwapper=()=>{document.body.classList.add("back-transition"),localStorage.getItem("theme")==="dark"?themeSetter("light"):localStorage.getItem("theme")==="light"&&themeSetter("dark")};localStorage.getItem("theme")==="light"?(localStorage.setItem("theme","light"),window.customThemeCallback&&customThemeCallback("light")):(themeSetter("dark"),document.addEventListener("DOMContentLoaded",blockSwitcher)),document.getElementById("chk").addEventListener("change",styleSwapper),window.addEventListener("scroll",()=>{let e=document.documentElement.scrollHeight-document.documentElement.clientHeight;if(e>=500){let t=document.body.scrollTop||document.documentElement.scrollTop,n=t/e*100;document.getElementById("scrollIndicator").style.width=n+"%"}})</script><section class=intro><div class=post-header><a class=go-back href=https://samyak.me/><svg aria-hidden="true" focusable="false" data-prefix="far" class="back-icon" data-icon="caret-square-left" height="25" role="img" viewBox="0 0 448 512"><path fill="currentcolor" d="M272 157.1v197.8c0 10.7-13 16.1-20.5 8.5l-98.3-98.9c-4.7-4.7-4.7-12.2.0-16.9l98.3-98.9c7.5-7.7 20.5-2.3 20.5 8.4zM448 80v352c0 26.5-21.5 48-48 48H48c-26.5.0-48-21.5-48-48V80c0-26.5 21.5-48 48-48h352c26.5.0 48 21.5 48 48zm-48 346V86c0-3.3-2.7-6-6-6H54c-3.3.0-6 2.7-6 6v340c0 3.3 2.7 6 6 6h340c3.3.0 6-2.7 6-6z"/></svg></a><h2 class=post-title>How is sound represented in code?</h2></div><div class=post-dets><div class=post-det-entry>9 min</div><div class=post-det-entry>November 5, 2024</div><div class=post-det-entry></div></div><span class=tags>Tagged:&nbsp;<h5><a class=tag href=https://samyak.me/tags/music>music</a></h5><h5><a class=tag href=https://samyak.me/tags/audio>audio</a></h5></span><div class=content><p>First, a disclaimer: I&rsquo;m not a musician, nor do I have any formal training in music. However, I have a genuine interest in it and have been learning guitar for a few months. I might get some music-related concepts wrong, so please feel free to correct me.</p><h1 id=what-is-sound-anyway>What is sound anyway?
<a class=heading-anchor href=#what-is-sound-anyway>#</a></h1><p>You might have learnt about sound as <em>waves</em> traveling through air. Air repeatedly gets compressed and expanded. Our ears perceive that as sound. <sup id=fnref:1><a href=#fn:1 class=footnote-ref role=doc-noteref>1</a></sup></p><img alt="a GIF of waves traveling through the air towards the right. The waves are created by a piston compressing the air from the left." src=/images/sound_wave_opt.gif style=max-width:100%><p>Another way to look at sound is <em>vibration</em>. When moving air hits the eardrum, it makes the drum vibrate and (oversimplifying it a lot) we perceive that as sound. It moves back and forth slightly from its resting position. <sup id=fnref:2><a href=#fn:2 class=footnote-ref role=doc-noteref>2</a></sup></p><img alt="a GIF of a membrane vibrating" src=/images/drum_vibration_opt.gif style=max-width:100%><h2 id=frequencies>Frequencies
<a class=heading-anchor href=#frequencies>#</a></h2><p>Both the waves and the vibrations happen very quickly. Humans can generally
<span class=sidenote><label class=sidenote-label for=sidenote-0>hear frequencies in the range of 20Hz to 20,000Hz.</label>
<input class=sidenote-checkbox type=checkbox checked id=sidenote-0></input>
<span class="sidenote-content sidenote-right">Those numbers are an ideal range. As we age, that range reduces a lot. If you&rsquo;re above 50, that range goes up to only 8000 or 12000Hz. <sup id=fnref:3><a href=#fn:3 class=footnote-ref role=doc-noteref>3</a></sup>
</span></span>1 Hertz (written as 1Hz) is one back and forth movement in one second. Imagine something vibrating 20,000 times a second!</p><p>The frequency of (western) music generally ranges from 30Hz to around 4200Hz.</p><p>Low-frequency sounds are deep and thick, which is referred to as low pitch. High-frequency sounds are thin and sharp, which is known as high pitch.</p><span class=sidenote><label class=sidenote-label for=sidenote-1>Here are two example sounds from a piano.</label>
<input class=sidenote-checkbox type=checkbox checked id=sidenote-1></input>
<span class="sidenote-content sidenote-right">However note (hehe) that a note on an instrument doesn't just consist of a single frequency.</span></span><figure style=margin:10px><figcaption>Low pitch (note A2):</figcaption><audio controls src=https://github.com/fuhton/piano-mp3/raw/refs/heads/master/piano-mp3/A2.mp3></audio></figure><figure style=margin:10px><figcaption>High pitch (note A6):</figcaption><audio controls src=https://github.com/fuhton/piano-mp3/raw/refs/heads/master/piano-mp3/A6.mp3></audio></figure><h1 id=how-do-we-represent-sound-as-data>How do we represent sound as data?
<a class=heading-anchor href=#how-do-we-represent-sound-as-data>#</a></h1><p>Now that we know that sound is just waves, let&rsquo;s look at the simplest wave. The <em>sine</em> wave. It is called so because it&rsquo;s the wave created by $$y = sin(x)$$</p><p>A wave has two important properties. The <em>amplitude</em> (A) is the maximum displacement from the reference value which, in this case, is 0. The second is <em>frequency</em> (f), which is how often the wave repeats and is usually measured in Hertz (Hz). For example, a sine wave of f=2Hz repeats the whole wave (from 0 to 0) twice in one second. In other words, the distance between two peaks of the wave is 1/f = 0.5 seconds.</p><p>For a sine wave with custom amplitude and frequency, the equation would be:</p><span class=sidenote><label class=sidenote-label for=sidenote-2>$$y = A \cdot sin(f \cdot x)$$</label>
<input class=sidenote-checkbox type=checkbox checked id=sidenote-2></input>
<span class="sidenote-content sidenote-right">Actually, the equation used for the exact chart below is $$y = A \cdot sin(2\pi \cdot f \cdot x)$$ A simple sin(x) wave repeats every 2π distance on the x-axis. The multiplication by 2π ensures it repeats every 1.0 distance on the x-axis (or every 1/f distance).</span></span><p>Here&rsquo;s an interactive chart. Tweak the amplitude and frequency values below and notice the changes in the waveform.</p><div id=graph-container></div><div class=slider-container><label for=amplitude>Amplitude: <span id=amplitudeValue>1</span></label>
<input type=range id=amplitude min=0.5 max=5 step=0.1 value=3.0><p><label for=frequency>Frequency: <span id=frequencyValue>1</span></label>
<input type=range id=frequency min=0.1 max=5 step=0.1 value=0.5></p></div><script type=module async src=/scripts/graphs1.js></script><style>.slider-container{display:flex;flex-wrap:wrap;align-items:center;margin-top:20px;gap:10px}label{white-space:nowrap}#samplePointsValue{min-width:2em;text-align:right}#samplePoints{flex-grow:1}</style><h3 id=into-a-digital-world>Into a digital world
<a class=heading-anchor href=#into-a-digital-world>#</a></h3><p>A wave is, by definition, <em>analog</em>. However, in code, we only deal with the digital. The 1s and 0s. One way to go from analog to digital is by <em>sampling</em>. That is, checking the amplitude at regular intervals and recording it. The regular interval is called the <em>sampling rate</em>.
Sampling never perfectly represents the source wave.</p><p>Here&rsquo;s a sine wave and a sampling of it represented by dots. We can try reconstructing it by connecting the dots. As can be expected, the reconstructed wave becomes more and more accurate as we increase the sampling rate. With a high enough sample rate, the sample is close enough to the original.</p><div id=graph-container-2></div><div class=slider-container><label for=samplePoints>Number of sample points:</label>
<span id=samplePointsValue>24</span>
<input type=range id=samplePoints min=3 max=99 value=24 step=3></div><script type=module async src=/scripts/graphs2.js></script><h3 id=are-we-data-yet>Are we data yet?
<a class=heading-anchor href=#are-we-data-yet>#</a></h3><p>Okay, so we now have the audio as a bunch of points on a graph. To represent a point as data, we simply take its x and y-coordinates. In this case, the x-axis is time and the y is amplitude.
So audio data is just a series of: $$[(t_1, a_1), (t_2, a_2), &mldr;, (t_n, a_n)]$$</p><p>Here is some of the data from the above chart, showing the sampled points.</p><div id=points1 class=pointList></div><style>.pointList{display:flex;flex-direction:row;flex-wrap:nowrap;white-space:nowrap;overflow-x:auto;font-family:monospace}.pointReprFirst,.pointReprLast{padding-right:12px}</style><h3 id=an-optimization>An optimization
<a class=heading-anchor href=#an-optimization>#</a></h3><p>You can notice a pattern in the data above. The points are always at a regular interval. So the x-values are always a multiple of some number. There are &ldquo;sampling rate&rdquo; number of points in one second of data. So the distance between a data point and the next is <code>1/(sampling rate)</code> seconds.</p><p>This is true even in the case of real-world audio data. We can assume that the data points (the amplitudes) are always sampled at the correct interval. This means we can drop the x-values entirely. Those values can be recreated entirely using the sampling rate. So audio data now is just an array of numbers!</p><div id=points2 class=pointList></div><p>Now we know that audio data can be specified using two things:</p><ol><li>The sampling rate. The unit for this is usually Hertz (Hz) or Kilohertz (kHz).</li><li>The amplitude of the audio at regular intervals. It&rsquo;s just a list/an array of numbers.</li></ol><h2 id=images---a-parallel>Images - a parallel
<a class=heading-anchor href=#images---a-parallel>#</a></h2><p>Let us look at something that is a little bit easier to see as data. An image. Here&rsquo;s an example of a simple black & white (also called grayscale) image <sup id=fnref:4><a href=#fn:4 class=footnote-ref role=doc-noteref>4</a></sup>:</p><p><img src=/images/plane.png alt="An image of a plane. Top view. An old airplane, might be a toy"></p><p>The resolution of this image is 256 pixels by 256 pixels. Totalling 65,536 pixels.
Each pixel is represented by a number. 0 (the minimum value) is black and
<span class=sidenote><label class=sidenote-label for=sidenote-7>255 (the maximum value) is white.</label>
<input class=sidenote-checkbox type=checkbox checked id=sidenote-7></input>
<span class="sidenote-content sidenote-right">This depends on the <a href=https://en.wikipedia.org/wiki/Color_depth>bit depth</a> of the image. The example image uses 8-bit color, hence the range of 0-255.</span></span></p><p>So to represent an image, all we need is the resolution (height, width) and a bunch of numbers. In this case, an array of 65,536 numbers.</p><p>An image can be seen as a 2-d matrix - numbers arranged in rows and columns:</p><p>$$
\begin{Bmatrix}
104 & 102 & &mldr; & 112 & 113 \\
\vdots & \vdots & \ddots & \vdots & \vdots\\
203 & 188 & &mldr; & 179 & 172
\end{Bmatrix}
$$</p><p>Color images are similar. Instead of one matrix, you have three separate ones for
<span class=sidenote><label class=sidenote-label for=sidenote-8>red, green and blue.</label>
<input class=sidenote-checkbox type=checkbox checked id=sidenote-8></input>
<span class="sidenote-content sidenote-right">RGB is only one of many <a href=https://en.wikipedia.org/wiki/Color_model>color models</a>.
</span></span>Another way is to represent each value in the matrix as a tuple of three values (r, g, b).</p><h2 id=back-to-audio>Back to audio
<a class=heading-anchor href=#back-to-audio>#</a></h2><p>That digression into image as data probably raises more questions than it answers, such as: What&rsquo;s the range of numbers in audio data? What&rsquo;s the <em>all black</em> and <em>all white</em> of audio?</p><p>The sine wave we saw earlier will give us some hint into the range of values. Unlike images, audio data can be negative too. The zero value is the resting position of the drum or the string. The vibration happens in both directions, hence the positive and negative values.</p><p>The actual range depends on the sample&rsquo;s <a href=https://en.wikipedia.org/wiki/Audio_bit_depth>bit depth</a>. 16-bit audio, for example, has values in the range -32,768 to +32,767. When processing audio, the data is usually
<span class=sidenote><label class=sidenote-label for=sidenote-9>converted to floating point and sometimes normalized to the range of -1.0 to 1.0.</label>
<input class=sidenote-checkbox type=checkbox checked id=sidenote-9></input>
<span class="sidenote-content sidenote-right">Why? I&rsquo;m not sure. It may be related to the fact that audio processing usually involves a lot of addition and multiplication. With integers, you would need to handle overflows and underflows.</span></span></p><h3 id=black-and-white>Black and white
<a class=heading-anchor href=#black-and-white>#</a></h3><p>Here&rsquo;s a sound sample with all zeros:</p><figure style=margin:10px><figcaption>Black:</figcaption><audio controls src=/audio/black.wav></audio></figure><p>You could try increasing the volume of your speakers, but you will hear nothing. As expected, it&rsquo;s silent. This is the all black of audio.</p><p>Now let&rsquo;s see a sample with all maximum values (+1.0 or +32,767). Maybe lower your volume before playing.</p><figure style=margin:10px><figcaption>White:</figcaption><audio controls src=/audio/white.wav></audio></figure><p>And&mldr; nothing? Try increasing the volume. You may hear two glitches or beeps—one at the beginning and another at the end. Imagine you press a drum&rsquo;s membrane and hold it there. Or pull a guitar&rsquo;s string and hold it. It won&rsquo;t make any sound, except at two instants—once when you press and another when you release.</p><p>This is a big difference between image and audio data. Sound is created by <em>movement</em>. If there&rsquo;s nothing changing across time, there&rsquo;s no sound. Audio is <em>temporal</em>. When the amplitude changes across time, like the sine wave we saw before, we get sound. A straight line is silence, no matter what amplitude it has.</p><p>In a way, <em>a piece of music is a painting in time</em>.</p><h2 id=channels>Channels
<a class=heading-anchor href=#channels>#</a></h2><p>Similar to the R, G, B-values of color images, sound too can have multiple <em>channels</em>. For example, most music is 2-channel. This is meant to be listened to with a pair of headphones. One channel for the left speaker and the other for the right. This is called
<span class=sidenote><label class=sidenote-label for=sidenote-10><em>stereo audio</em></label>
<input class=sidenote-checkbox type=checkbox checked id=sidenote-10></input>
<span class="sidenote-content sidenote-right">You might have also heard of <a href=https://en.wikipedia.org/wiki/5.1_surround_sound>5.1 channel audio</a> usually in the context of movies and home theatres.</span></span></p><p>The way multi-channel audio is represented as data is similar to images. One method is to have multiple separate arrays of data—one array for each channel:</p><p>$$
Ch_1 = [Ch_1t_1,\thickspace Ch_1t_2,\thickspace Ch_1t_3,\thickspace &mldr;]\\
Ch_2 = [Ch_2t_1,\thickspace Ch_2t_2,\thickspace Ch_2t_3,\thickspace &mldr;]\\
\vdots\\
Ch_n = [Ch_nt_1,\thickspace Ch_nt_2,\thickspace Ch_nt_3,\thickspace &mldr;]\\
$$</p><p>Alternatively, we can have a single array where each time step is represented by N numbers—one for each channel—arranged sequentially: N numbers for time1, then N numbers for time2, and so on:
$$
[Ch_1t_1,\thickspace Ch_2t_1,\thickspace &mldr;,\thickspace Ch_nt_1,\thickspace Ch_1t_2,\thickspace Ch_2t_2,\thickspace &mldr;,\thickspace Ch_nt_2, &mldr;]
$$</p><h1 id=conclusion>Conclusion
<a class=heading-anchor href=#conclusion>#</a></h1><p>Putting all of that together, sound is represented using these three properties:</p><ol><li>The sampling rate. Example: 44.1kHz.</li><li>The number of channels. Example: 2.</li><li>An array of numbers representing the amplitude at regular intervals (1/(sampling rate) seconds) and for each channel.</li></ol><h1 id=further-reading>Further reading
<a class=heading-anchor href=#further-reading>#</a></h1><p>What can we do with this data? Since audio is just a signal, we can use digital signal processing (DSP) algorithms on it. One such process is the Fourier Transform, which can help find out the frequencies present in the audio data. There&rsquo;s a class of algorithms for efficiently calculating the fourier transform of a signal in code—the <a href=https://en.wikipedia.org/wiki/Fast_Fourier_transform>Fast Fourier Transform</a>.</p><p>You can start playing around with audio data in code. There are libraries in most languages for reading sound from your device&rsquo;s mic or by reading a wav, mp3, etc file. Here are some popular ones:</p><ul><li>Python:<ul><li>Libraries for audio I/O: <a href=https://github.com/spatialaudio/python-sounddevice>python-sounddevice</a> - has a simple interface for reading audio as a numpy array given the number of seconds, sample rate and number of channels.</li><li>Libraries for audio processing: SciPy - <a href=https://docs.scipy.org/doc/scipy/tutorial/fft.html>fourier transforms</a>.</li></ul></li><li>Rust: <a href=https://rust.audio/>rust.audio</a> is a good collection of resources. Some mentions:<ul><li><a href=https://github.com/rustaudio/cpal>cpal</a> - audio I/O library. This is not the simplest library to start with. It took me a while to figure out reading audio data into a Vec.</li><li><a href=https://github.com/SamiPerttu/fundsp>fundsp</a> - audio synthesis library. You can create sounds, maybe even music, with just code. I have not used it extensively—only the basics to generate test cases for audio applications.</li><li><a href=https://github.com/ejmahler/RustFFT>rustfft</a></li></ul></li></ul><div class=footnotes role=doc-endnotes><hr><ol><li id=fn:1><p>Source of the image: <a href=https://blog.soton.ac.uk/soundwaves/wave-basics/ways-of-showing-waves/>Ways of showing waves by The University of Southampton</a>&#160;<a href=#fnref:1 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:2><p>Source of the image: <a href=https://www.acs.psu.edu/drussell/Demos/MembraneCircle/Circle.html>Vibrational Modes of a Circular Membrane by Dan Russell</a>&#160;<a href=#fnref:2 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:3><p>Source: <a href=https://www.sciencedirect.com/science/article/pii/S2666606521000407>Patterns of hearing changes in women and men from denarians to nonagenarians</a> by Wasano et al.&#160;<a href=#fnref:3 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:4><p>Source: <a href="https://sipi.usc.edu/database/database.php?volume=misc&amp;image=16#top">Database of test images</a>&#160;<a href=#fnref:4 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li></ol></div></div></section><footer id=footer><strong></strong><div class=social>&nbsp; <a href=https://github.com/Samyak2 target=_blank rel=noopener title=Github><svg width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M9 19c-5 1.5-5-2.5-7-3m14 6v-3.87a3.37 3.37.0 00-.94-2.61c3.14-.35 6.44-1.54 6.44-7A5.44 5.44.0 0020 4.77 5.07 5.07.0 0019.91 1S18.73.65 16 2.48a13.38 13.38.0 00-7 0C6.27.65 5.09 1 5.09 1A5.07 5.07.0 005 4.77 5.44 5.44.0 003.5 8.55c0 5.42 3.3 6.61 6.44 7A3.37 3.37.0 009 18.13V22"/></svg></a> &nbsp;&nbsp; <a href=mailto:samyak201@gmail.com target=_blank rel=noopener title=Email><svg width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M4 4h16c1.1.0 2 .9 2 2v12c0 1.1-.9 2-2 2H4c-1.1.0-2-.9-2-2V6c0-1.1.9-2 2-2z"/><polyline points="22,6 12,13 2,6"/></svg></a> &nbsp;&nbsp; <a href=https://twitter.com/Samyak210 target=_blank rel=noopener title=Twitter><svg width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M23 3a10.9 10.9.0 01-3.14 1.53 4.48 4.48.0 00-7.86 3v1A10.66 10.66.0 013 4s-4 9 5 13a11.64 11.64.0 01-7 2c9 5 20 0 20-11.5a4.5 4.5.0 00-.08-.83A7.72 7.72.0 0023 3z"/></svg></a> &nbsp;&nbsp; <a href=https://hachyderm.io/@samyak target=_blank rel=me title=Mastodon><svg width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2"><path d="M23.193 7.879c0-5.206-3.411-6.732-3.411-6.732C18.062.357 15.108.025 12.041.0h-.076c-3.068.025-6.02.357-7.74 1.147.0.0-3.411 1.526-3.411 6.732.0 1.192-.023 2.618.015 4.129.124 5.092.934 10.109 5.641 11.355 2.17.574 4.034.695 5.535.612 2.722-.15 4.25-.972 4.25-.972l-.09-1.975s-1.945.613-4.129.539c-2.165-.074-4.449-.233-4.799-2.891a5.499 5.499.0 01-.048-.745s2.125.52 4.817.643c1.646.075 3.19-.097 4.758-.283 3.007-.359 5.625-2.212 5.954-3.905.517-2.665.475-6.507.475-6.507zm-4.024 6.709h-2.497V8.469c0-1.29-.543-1.944-1.628-1.944-1.2.0-1.802.776-1.802 2.312v3.349h-2.483v-3.35c0-1.536-.602-2.312-1.802-2.312-1.085.0-1.628.655-1.628 1.944v6.119H4.832V8.284c0-1.289.328-2.313.987-3.07.68-.758 1.569-1.146 2.674-1.146 1.278.0 2.246.491 2.886 1.474L12 6.585l.622-1.043c.64-.983 1.608-1.474 2.886-1.474 1.104.0 1.994.388 2.674 1.146.658.757.986 1.781.986 3.07v6.304z"/></svg></a> &nbsp;</div><strong></strong><p style=color:grey>© 2021-2025 Samyak Sarnayak. <a href=https://creativecommons.org/licenses/by-nc-sa/4.0/>Some rights reserved</a>.</p></footer></div></body></html>